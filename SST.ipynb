{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SST.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1A_gTKVn15l7f7DMrvDu3geu9ChnBrBtz",
      "authorship_tag": "ABX9TyMWa6XzvzVEYTpwSguYYyUF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunbo777/twig_farm_nlp/blob/main/SST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAYKgwoAhnA0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEOhVQgQIbRz",
        "outputId": "555a1e63-9314-4cf0-900d-fb8b8ef1ffd3"
      },
      "source": [
        "!git clone https://github.com/chunbo777/Stable-Style-Transformer\n",
        "!git clone https://github.com/lijuncen/Sentiment-and-Style-Transfer\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "%cd /content/Stable-Style-Transformer/generation_model/yelp"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Stable-Style-Transformer'...\n",
            "remote: Enumerating objects: 265, done.\u001b[K\n",
            "remote: Counting objects: 100% (265/265), done.\u001b[K\n",
            "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
            "remote: Total 265 (delta 139), reused 249 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (265/265), 1.54 MiB | 6.70 MiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n",
            "Cloning into 'Sentiment-and-Style-Transfer'...\n",
            "remote: Enumerating objects: 392, done.\u001b[K\n",
            "remote: Total 392 (delta 0), reused 0 (delta 0), pack-reused 392\u001b[K\n",
            "Receiving objects: 100% (392/392), 61.34 MiB | 33.66 MiB/s, done.\n",
            "Resolving deltas: 100% (149/149), done.\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "/content/Stable-Style-Transformer/generation_model/yelp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoCa-XnHL3-A",
        "outputId": "90f5b6fc-7456-41d4-e091-f86a7f4c144a"
      },
      "source": [
        "pip install tensorboardX"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.4)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLQsP64vdusf",
        "outputId": "47d78930-bf1b-4209-d007-07ef3dd34884"
      },
      "source": [
        "cd /content/Stable-Style-Transformer/generation_model/yelp/classifier"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Stable-Style-Transformer/generation_model/yelp/classifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "HQky4Bdwb9O1",
        "outputId": "96066d0c-db7f-4ae9-dec7-cf5af2cb9e2f"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "\n",
        "from transformers import *\n",
        "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "\n",
        "## 초기화\n",
        "from dis_model import *\n",
        "dismodel = findattribute().cuda()\n",
        "dismodel.train()\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "summary = SummaryWriter(logdir='./logs')\n",
        "\n",
        "def main():    \n",
        "    f = open('../gpt_yelp_vocab.json')\n",
        "    token2num = json.load(f)\n",
        "\n",
        "    num2token = {}\n",
        "    for key, value in token2num.items():\n",
        "        num2token[value] = key\n",
        "    f.close()\n",
        "\n",
        "    data_path = \"/content/Sentiment-and-Style-Transfer/data\" # customize data path\n",
        "    yelp_neg_path = data_path + \"/yelp/sentiment.train.0\"\n",
        "    yelp_neg_open = open(yelp_neg_path, \"r\")\n",
        "    yelp_neg_dataset = yelp_neg_open.readlines()\n",
        "    neg_len = len(yelp_neg_dataset)\n",
        "    yelp_neg_open.close()\n",
        "\n",
        "    yelp_pos_path = data_path + \"/yelp/sentiment.train.1\"\n",
        "    yelp_pos_open = open(yelp_pos_path, \"r\")\n",
        "    yelp_pos_dataset = yelp_pos_open.readlines()\n",
        "    pos_len = len(yelp_pos_dataset)\n",
        "    yelp_pos_open.close()\n",
        "\n",
        "    \"\"\"training parameter\"\"\"\n",
        "    cls_initial_lr = 0.001\n",
        "    cls_trainer = optim.Adamax(dismodel.cls_params, lr=cls_initial_lr) # initial 0.001\n",
        "    max_grad_norm = 25\n",
        "    batch = 1\n",
        "    epoch = 5\n",
        "    stop_point = pos_len*epoch\n",
        "    \n",
        "    pre_epoch = 0\n",
        "    for start in tqdm(range(0, stop_point)):\n",
        "        ## learing rate decay\n",
        "        now_epoch = (start+1)//pos_len\n",
        "        if now_epoch == 4:\n",
        "            cls_initial_lr = cls_initial_lr/2            \n",
        "            cls_trainer = optim.Adamax(dismodel.cls_params, lr=cls_initial_lr) # initial 0.001\n",
        "            \n",
        "        \"\"\"data start point\"\"\"\n",
        "        neg_start = start%neg_len\n",
        "        pos_start = start%pos_len\n",
        "\n",
        "        \"\"\"data setting\"\"\"\n",
        "        neg_sentence = yelp_neg_dataset[neg_start].strip()\n",
        "        pos_sentence = yelp_pos_dataset[pos_start].strip()                \n",
        "\n",
        "        neg_labels = [] # negative labels\n",
        "        neg_labels.append([1,0])\n",
        "        neg_attribute = torch.from_numpy(np.asarray(neg_labels)).type(torch.FloatTensor).cuda()\n",
        "\n",
        "        pos_labels = [] # positive labels\n",
        "        pos_labels.append([0,1])\n",
        "        pos_attribute = torch.from_numpy(np.asarray(pos_labels)).type(torch.FloatTensor).cuda()\n",
        "\n",
        "        sentences = [neg_sentence, pos_sentence]\n",
        "        attributes = [neg_attribute, pos_attribute]\n",
        "\n",
        "        \"\"\"data input\"\"\"\n",
        "        for i in range(2):\n",
        "            # k=0: negative, k=1: positive\n",
        "            sentence = sentences[i]\n",
        "            attribute = attributes[i] # for generate\n",
        "\n",
        "            token_idx = torch.tensor(gpt_tokenizer.encode(sentence)).unsqueeze(0).cuda()\n",
        "            \n",
        "            dis_out = dismodel.discriminator(token_idx)\n",
        "\n",
        "            \"\"\"calculation loss & traning\"\"\"\n",
        "            # training using discriminator loss\n",
        "            cls_loss = dismodel.cls_loss(attribute, dis_out)\n",
        "            summary.add_scalar('discriminator loss', cls_loss.item(), start)\n",
        "\n",
        "            cls_trainer.zero_grad()\n",
        "            cls_loss.backward() # retain_graph=True\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(dismodel.cls_params, max_grad_norm)            \n",
        "            cls_trainer.step()\n",
        "        \n",
        "        \"\"\"savining point\"\"\"\n",
        "        if (start+1)%pos_len == 0:\n",
        "            random.shuffle(yelp_neg_dataset)\n",
        "            random.shuffle(yelp_pos_dataset)\n",
        "            save_model((start+1)//pos_len)        \n",
        "    save_model('final') # final_model    \n",
        "\n",
        "    \n",
        "def save_model(iter):\n",
        "    if not os.path.exists('/content/drive/MyDrive/models2/'):\n",
        "        os.makedirs('/content/drive/MyDrive/models2/')\n",
        "    torch.save(dismodel.state_dict(), '/content/drive/MyDrive/models2/cls_model_{}'.format(iter))  \n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    torch.cuda.empty_cache()\n",
        "    main()\n",
        "    \n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f4091dfd87fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-f4091dfd87fb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../gpt_yelp_vocab.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mtoken2num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../gpt_yelp_vocab.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwbLL3Cp9srB",
        "outputId": "ea84e44b-086a-4094-8c78-43c135d8f46d"
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5mXX4q97Qhc",
        "outputId": "1176dff6-fc0d-40f6-a258-63cbf5d17414"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Stable-Style-Transformer/generation_model/yelp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azcxm5xJ7VSl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "Mor6rNIWIjZh",
        "outputId": "a316d22f-101a-4bbd-9a98-1af607f98cb6"
      },
      "source": [
        "#gen_model, train.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "\n",
        "from transformers import *\n",
        "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "\n",
        "## 초기화\n",
        "from gen_model import *\n",
        "genmodel = styletransfer().cuda()\n",
        "genmodel.train()\n",
        "\n",
        "sys.path.insert(0, \"/content/Stable-Style-Transformer/generation_model/yelp/classifier\")\n",
        "from dis_model import *\n",
        "dismodel = findattribute().cuda()\n",
        "dismodel_name='cls_model_3'\n",
        "dismodel.load_state_dict(torch.load('/content/drive/MyDrive/models2/{}'.format(dismodel_name)))\n",
        "dismodel.eval()\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "summary = SummaryWriter(logdir='./logs')\n",
        "\n",
        "def main():    \n",
        "    f = open('/content/Stable-Style-Transformer/generation_model/yelp/gpt_yelp_vocab.json')\n",
        "    token2num = json.load(f)\n",
        "\n",
        "    num2token = {}\n",
        "    for key, value in token2num.items():\n",
        "        num2token[value] = key\n",
        "    f.close()\n",
        "\n",
        "    data_path = \"\"\n",
        "    train_yelp_neg_path = data_path + \"/content/Sentiment-and-Style-Transfer/data/yelp/sentiment.train.0\"\n",
        "    train_yelp_neg_open = open(train_yelp_neg_path, \"r\")\n",
        "    train_yelp_neg_dataset = train_yelp_neg_open.readlines()\n",
        "    yelp_neg_dataset = train_yelp_neg_dataset\n",
        "    \n",
        "    neg_len = len(yelp_neg_dataset)\n",
        "    train_yelp_neg_open.close()\n",
        "\n",
        "    train_yelp_pos_path = data_path + \"/content/Sentiment-and-Style-Transfer/data/yelp/sentiment.train.1\"\n",
        "    train_yelp_pos_open = open(train_yelp_pos_path, \"r\")\n",
        "    train_yelp_pos_dataset = train_yelp_pos_open.readlines()\n",
        "    yelp_pos_dataset = train_yelp_pos_dataset\n",
        "    \n",
        "    pos_len = len(yelp_pos_dataset)\n",
        "    train_yelp_pos_open.close()\n",
        "\n",
        "    \"\"\"training parameter\"\"\"\n",
        "    aed_initial_lr = 0.00001\n",
        "    gen_initial_lr = 0.001\n",
        "    aed_trainer = optim.Adamax(genmodel.aed_params, lr=aed_initial_lr) # initial 0.0005\n",
        "    gen_trainer = optim.Adamax(genmodel.aed_params, lr=gen_initial_lr) # initial 0.0001\n",
        "    max_grad_norm = 20\n",
        "    batch = 1\n",
        "    epoch = 6\n",
        "    stop_point = pos_len*epoch\n",
        "    \n",
        "    pre_epoch = 0\n",
        "    for start in tqdm(range(0, stop_point)):\n",
        "        ## learing rate decay\n",
        "        now_epoch = (start+1)//pos_len\n",
        "            \n",
        "        \"\"\"data start point\"\"\"\n",
        "        neg_start = start%neg_len\n",
        "        pos_start = start%pos_len\n",
        "\n",
        "        \"\"\"data setting\"\"\"\n",
        "        neg_sentence = yelp_neg_dataset[neg_start].strip()\n",
        "        pos_sentence = yelp_pos_dataset[pos_start].strip()                \n",
        "\n",
        "        neg_labels = [] # negative labels\n",
        "        neg_labels.append([1,0])\n",
        "        neg_attribute = torch.from_numpy(np.asarray(neg_labels)).type(torch.FloatTensor).cuda()\n",
        "\n",
        "        pos_labels = [] # positive labels\n",
        "        pos_labels.append([0,1])\n",
        "        pos_attribute = torch.from_numpy(np.asarray(pos_labels)).type(torch.FloatTensor).cuda()\n",
        "\n",
        "        sentences = [neg_sentence, pos_sentence]\n",
        "        attributes = [neg_attribute, pos_attribute]\n",
        "        sentiments = [0, 1]\n",
        "\n",
        "        \"\"\"data input\"\"\"\n",
        "        for i in range(2):\n",
        "            # k=0: negative, k=1: positive\n",
        "            sentence = sentences[i]\n",
        "            attribute = attributes[i] # for decoder\n",
        "            fake_attribute = attributes[abs(1-i)] # for generate\n",
        "#             sentiment = sentiments[i] # for delete\n",
        "\n",
        "            token_idx = torch.tensor(gpt_tokenizer.encode(sentence)).unsqueeze(0).cuda()\n",
        "\n",
        "            # delete model\n",
        "            max_len = int(token_idx.shape[1]/2)\n",
        "            dis_out = dismodel.discriminator(token_idx)    \n",
        "            sentiment = dis_out.argmax(1).cpu().item() ## 변경점 for delete\n",
        "            \n",
        "            del_idx = token_idx\n",
        "            for k in range(max_len):\n",
        "                del_idx = dismodel.att_prob(del_idx, sentiment)                \n",
        "                dis_out = dismodel.discriminator(del_idx)    \n",
        "                sent_porb = F.softmax(dis_out, 1).squeeze(0)[sentiment].cpu().detach().numpy().item()\n",
        "                if sent_porb < 0.7:\n",
        "                    break       \n",
        "                    \n",
        "            \"\"\"auto-encoder loss & traning\"\"\"\n",
        "            # training using discriminator loss\n",
        "            enc_out = genmodel.encoder(del_idx)\n",
        "            dec_out, vocab_out = genmodel.decoder(enc_out, token_idx, attribute)\n",
        "\n",
        "            ## calculation loss\n",
        "            recon_loss = genmodel.recon_loss(token_idx, vocab_out)\n",
        "            summary.add_scalar('reconstruction loss', recon_loss.item(), start)\n",
        "            \n",
        "            aed_trainer.zero_grad()\n",
        "            recon_loss.backward(retain_graph=True) # retain_graph=True\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(genmodel.aed_params, max_grad_norm)            \n",
        "            aed_trainer.step()\n",
        "            \n",
        "            \"\"\"decoder classification loss & training\"\"\"\n",
        "            ## calculation loss\n",
        "            gen_cls_out = dismodel.gen_discriminator(vocab_out)\n",
        "\n",
        "            ## calculation loss\n",
        "            gen_cls_loss = genmodel.cls_loss(attribute, gen_cls_out)\n",
        "            summary.add_scalar('generated sentence loss', gen_cls_loss.item(), start)\n",
        "\n",
        "            gen_trainer.zero_grad()\n",
        "            gen_cls_loss.backward() # retain_graph=True\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(genmodel.aed_params, max_grad_norm)\n",
        "            gen_trainer.step()\n",
        "            \n",
        "        \n",
        "        \"\"\"savining point\"\"\"\n",
        "        if (start+1)%pos_len == 0:\n",
        "            random.shuffle(yelp_neg_dataset)\n",
        "            random.shuffle(yelp_pos_dataset)\n",
        "            save_model((start+1)//pos_len)        \n",
        "    save_model('final') # final_model    \n",
        "\n",
        "    \n",
        "def save_model(iter):\n",
        "    if not os.path.exists('/content/drive/MyDrive/model_gen'):\n",
        "        os.makedirs('/content/drive/MyDrive/model_gen/')\n",
        "    torch.save(genmodel.state_dict(), '/content/drive/MyDrive/model_gen/gen_model_{}'.format(iter))  \n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    torch.cuda.empty_cache()\n",
        "    main()\n",
        "    \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1596246 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-14e39d94263e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-14e39d94263e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mgen_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mgen_cls_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# retain_graph=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maed_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mgen_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [256, 50259]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "sSvp-N6dbtra",
        "outputId": "9c616e16-30a7-4cea-f955-af2184ff1bed"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Stable-Style-Transformer/generation_model/yelp'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB11wyBMJukq"
      },
      "source": [
        "#yelp.classifier의 dis_model\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, \"/DATA/joosung/fairseq_master\")\n",
        "\n",
        "class findattribute(nn.Module):\n",
        "    def __init__(self, drop_rate=0, gpu = True):\n",
        "        super(findattribute, self).__init__()\n",
        "        self.gpu = gpu\n",
        "        \n",
        "        self.n_vocab = 50259\n",
        "        self.emb_dim = 256\n",
        "        \n",
        "        \"\"\"idx & length\"\"\"\n",
        "        self.START_IDX = 50257\n",
        "        self.PAD_IDX = 50258\n",
        "        self.EOS_IDX = 50256\n",
        "        \n",
        "        \"\"\"Discriminator(classifier)\"\"\"\n",
        "        self.word_dim = 256\n",
        "        self.word_emb = nn.Embedding(self.n_vocab, self.word_dim, self.PAD_IDX) # 50265x1024\n",
        "        \n",
        "        self.channel_out = 100\n",
        "        self.conv2d_2 = nn.Conv2d(1,self.channel_out,(2,self.word_dim))\n",
        "        self.conv2d_3 = nn.Conv2d(1,self.channel_out,(3,self.word_dim))\n",
        "        self.conv2d_4 = nn.Conv2d(1,self.channel_out,(4,self.word_dim))\n",
        "        self.conv2d_5 = nn.Conv2d(1,self.channel_out,(5,self.word_dim))\n",
        "#         self.fc_drop = nn.Dropout(drop_rate)\n",
        "        self.disc_fc = nn.Linear(4*self.channel_out, 2)\n",
        "        \n",
        "        \"\"\"parameters\"\"\"                \n",
        "        self.cls_params = list(self.word_emb.parameters())+list(self.conv2d_2.parameters())+list(self.conv2d_3.parameters())+list(self.conv2d_4.parameters())+\\\n",
        "        list(self.conv2d_5.parameters())+list(self.disc_fc.parameters())\n",
        "            \n",
        "\n",
        "    def discriminator(self, token_idx):\n",
        "        \"\"\"\n",
        "        token_idx: (batch, seq_len)\n",
        "        \"\"\"\n",
        "        if token_idx.shape[1] < 5:\n",
        "            padding_size = 5-token_idx.shape[1]\n",
        "            padding_token = []\n",
        "            for k in range(token_idx.shape[0]):\n",
        "                temp = []\n",
        "                for i in range(padding_size):\n",
        "                    temp.append(self.PAD_IDX)\n",
        "                padding_token.append(temp)                \n",
        "            padding_token=torch.from_numpy(np.array(padding_token))\n",
        "            if self.gpu == True:\n",
        "                padding_token = padding_token.cuda()\n",
        "            token_idx=torch.cat([token_idx,padding_token], 1) # (batch, seq_len+padding) = (batch, 5)\n",
        "\n",
        "        word_emb = self.word_emb(token_idx) # (batch, seq_len, word_dim)\n",
        "        word_2d = word_emb.unsqueeze(1) # (batch, 1, seq_len, word_dim)\n",
        "\n",
        "        x2 = F.relu(self.conv2d_2(word_2d)).squeeze(3) # bi-gram, (batch, channel_out, seq_len-1)\n",
        "        x3 = F.relu(self.conv2d_3(word_2d)).squeeze(3) # 3-gram, (batch, channel_out, seq_len-2)\n",
        "        x4 = F.relu(self.conv2d_4(word_2d)).squeeze(3) # 4-gram, (batch, channel_out, seq_len-3)\n",
        "        x5 = F.relu(self.conv2d_5(word_2d)).squeeze(3) # 5-gram, (batch, channel_out, seq_len-4)\n",
        "\n",
        "        # Max-over-time-pool\n",
        "        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x4 = F.max_pool1d(x4, x4.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x5 = F.max_pool1d(x5, x5.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x = torch.cat([x2, x3, x4, x5], dim=1) # (batch, channel_out*4)\n",
        "\n",
        "        y = self.disc_fc(x) # (batch, 2)\n",
        "\n",
        "        if self.gpu == True:\n",
        "            return y.cuda()\n",
        "        else:\n",
        "            return y\n",
        "        \n",
        "    def gen_discriminator(self, gen_out):\n",
        "        \"\"\"\n",
        "        gen_out: (gen_len+2, batch, n_vocab)\n",
        "        \"\"\"\n",
        "        gen_emb = gen_out[1:-1,:,:] # (gen_len, batch, n_vocab)\n",
        "        gen_emb = torch.bmm(gen_emb, self.word_emb.weight.repeat(gen_emb.shape[0],1,1))\n",
        "        # (gen_len, batch, emb_dim) = (gen_len, batch, n_vocab) x (gen_len, n_vocab, emb_dim)\n",
        "        gen_emb = gen_emb.transpose(0, 1) # (batch, gen_len, word_dim)\n",
        "        \n",
        "        if gen_emb.shape[1] < 5:\n",
        "            padding_size = 5-gen_emb.shape[1]\n",
        "            padding_token = []\n",
        "            for k in range(gen_emb.shape[0]):\n",
        "                temp = []\n",
        "                for i in range(padding_size):\n",
        "                    temp.append(self.PAD_IDX)\n",
        "                padding_token.append(temp)                \n",
        "            padding_token=torch.from_numpy(np.array(padding_token)) # (batch, padding_len)\n",
        "            if self.gpu == True:\n",
        "                padding_token = padding_token.cuda()\n",
        "            padding_emb = self.word_emb(padding_token) # (batch, padding_len, emb_dim)\n",
        "            gen_emb = torch.cat([gen_emb, padding_emb], 1) # (batch, 5, emb_dim)   \n",
        "            \n",
        "        word_2d = gen_emb.unsqueeze(1) # (batch, 1, seq_len, word_dim)\n",
        "\n",
        "        x2 = F.relu(self.conv2d_2(word_2d)).squeeze(3) # bi-gram, (batch, channel_out, seq_len-1)\n",
        "        x3 = F.relu(self.conv2d_3(word_2d)).squeeze(3) # 3-gram, (batch, channel_out, seq_len-2)\n",
        "        x4 = F.relu(self.conv2d_4(word_2d)).squeeze(3) # 4-gram, (batch, channel_out, seq_len-3)\n",
        "        x5 = F.relu(self.conv2d_5(word_2d)).squeeze(3) # 5-gram, (batch, channel_out, seq_len-4)\n",
        "\n",
        "        # Max-over-time-pool\n",
        "        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x4 = F.max_pool1d(x4, x4.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x5 = F.max_pool1d(x5, x5.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x = torch.cat([x2, x3, x4, x5], dim=1) # (batch, channel_out*4)\n",
        "\n",
        "        y = self.disc_fc(x) # (batch, 2)\n",
        "\n",
        "        if self.gpu == True:\n",
        "            return y.cuda()\n",
        "        else:\n",
        "            return y\n",
        "        \n",
        "    def att_prob(self, token_idx, sentiment):\n",
        "        \"\"\"\n",
        "        token_idx: (batch, seq_len)\n",
        "        \"\"\"\n",
        "#         if token_idx.size(1) < 5:\n",
        "#             padding_size = 5-token_idx.size(1)\n",
        "#             padding_token = []\n",
        "#             for k in range(token_idx.size(0)):\n",
        "#                 temp = []\n",
        "#                 for i in range(padding_size):\n",
        "#                     temp.append(self.PAD_IDX)\n",
        "#                 padding_token.append(temp)                \n",
        "#             padding_token=torch.from_numpy(np.array(padding_token))\n",
        "#             if self.gpu == True:\n",
        "#                 padding_token = padding_token.cuda()\n",
        "#             token_idx=torch.cat([token_idx,padding_token], 1) # (batch, seq_len+padding) = (batch, 5)\n",
        "        token_list = token_idx.squeeze(0).cpu().tolist() # list\n",
        "        min_prob = 1\n",
        "        for i in range(len(token_list)):\n",
        "            del_list = token_list[:i] + token_list[i+1:]\n",
        "            del_tensor = torch.from_numpy(np.asarray(del_list)).unsqueeze(0).cuda()\n",
        "            del_prob=F.softmax(self.discriminator(del_tensor),1).squeeze(0)[sentiment].cpu().detach().numpy().item()\n",
        "            \n",
        "            if del_prob <= min_prob:                \n",
        "                max_ind = i\n",
        "                min_prob = del_prob\n",
        "                \n",
        "        final_list = token_list[:max_ind] + token_list[max_ind+1:]\n",
        "        del_idx = torch.from_numpy(np.asarray(final_list)).unsqueeze(0).cuda()\n",
        "        return del_idx    \n",
        "        \n",
        "    def cls_loss(self, targets, cls_out):\n",
        "        \"\"\"\n",
        "        targets: (batch, 2) / attributes [0,1] or [1,0]\n",
        "        cls_out: (batch, 2) (logits)\n",
        "        \"\"\"\n",
        "        \n",
        "        final_targets = targets.argmax(1) # (batch)\n",
        "        cls_loss = F.cross_entropy(cls_out, final_targets)\n",
        "        \n",
        "        if self.gpu == True:       \n",
        "            return cls_loss.cuda()\n",
        "        else:\n",
        "            return cls_loss\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}